{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Day 2\n",
    "\n",
    "In this analysis - inspired by  [Wulff & Mata, 2025](https://doi.org/10.1038/s41562-024-02089-y) - we will use a language model to extract features from personality items. We will then use these features to compute the similarity between items, evaluate how well these predict observed similarities, and visualize the similarity matrix in two dimensions. Finally, we will re-assign each item to a personality construct based on its predicted similarity to the constructs.\n",
    "\n",
    "By the end of this analysis, you will have learned how:\n",
    "- To extract features from text using a pre-trained langauge model\n",
    "- To compute the similarity between items using cosine similarity\n",
    "- How this can be used to predict the construct to which an item belongs, and thus potentially improve construct validity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5de300fe5f3a4f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment Setup "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fd071af86227f3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:  # If in Google Colab environment\n",
    "    # Mount google drive to enable access to data files\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Installing requisite packages\n",
    "    !pip install pacmap sentence-transformers &> /dev/null\n",
    "\n",
    "    # Change working directory\n",
    "    %cd /content/drive/MyDrive/LLM4BeSci_Zurich2025/day_1"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pacmap import PaCMAP\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-09T13:01:16.578652Z",
     "start_time": "2025-12-09T13:01:10.132622Z"
    }
   },
   "id": "b9597ed3f5b8655f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extracting Features from Personality Items\n",
    "\n",
    "We begin by loading the personality items into a `pandas.DataFrame` with three columns:\n",
    "\n",
    "1. `factor`: The (high-level) personality factor to which the item belongs.\n",
    "2. `construct`: The (mid-level) personality construct to which the item belongs.\n",
    "3. `item`: The text of the personality item used to measure the construct.\n",
    "\n",
    "Run the cell below."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad379710e7b3b58d"
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading personality data\n",
    "personality = pd.read_csv('items.csv') \n",
    "personality"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-09T13:01:25.677935Z",
     "start_time": "2025-12-09T13:01:25.662958Z"
    }
   },
   "id": "3e0f28c32454e9eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                factor             construct  \\\n",
       "0    Conscientiousness  Achievement-Striving   \n",
       "1    Conscientiousness  Achievement-Striving   \n",
       "2    Conscientiousness  Achievement-Striving   \n",
       "3    Conscientiousness  Achievement-Striving   \n",
       "4    Conscientiousness  Achievement-Striving   \n",
       "..                 ...                   ...   \n",
       "295        Neuroticism         Vulnerability   \n",
       "296        Neuroticism         Vulnerability   \n",
       "297        Neuroticism         Vulnerability   \n",
       "298        Neuroticism         Vulnerability   \n",
       "299        Neuroticism         Vulnerability   \n",
       "\n",
       "                                          item  \n",
       "0                    Go straight for the goal.  \n",
       "1         Plunge into tasks with all my heart.  \n",
       "2                              Demand quality.  \n",
       "3    Set high standards for myself and others.  \n",
       "4                     Turn plans into actions.  \n",
       "..                                         ...  \n",
       "295                Remain calm under pressure.  \n",
       "296          Am calm even in tense situations.  \n",
       "297               Can handle complex problems.  \n",
       "298                 Readily overcome setbacks.  \n",
       "299                          Know how to cope.  \n",
       "\n",
       "[300 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>construct</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>Achievement-Striving</td>\n",
       "      <td>Go straight for the goal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>Achievement-Striving</td>\n",
       "      <td>Plunge into tasks with all my heart.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>Achievement-Striving</td>\n",
       "      <td>Demand quality.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>Achievement-Striving</td>\n",
       "      <td>Set high standards for myself and others.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>Achievement-Striving</td>\n",
       "      <td>Turn plans into actions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>Vulnerability</td>\n",
       "      <td>Remain calm under pressure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>Vulnerability</td>\n",
       "      <td>Am calm even in tense situations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>Vulnerability</td>\n",
       "      <td>Can handle complex problems.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>Vulnerability</td>\n",
       "      <td>Readily overcome setbacks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>Vulnerability</td>\n",
       "      <td>Know how to cope.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code below makes use of the `all-MiniLM-L6-v2` model to extract features from the personality items. It loads the model using the `sentence_transformers` library and extract a vector of features for each item with the `encode` method. It then converts the features to a `pandas.DataFrame` for further analysis and for easy viewing.\n",
    "\n",
    "Run the cell below."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3eccef1aa842976a"
  },
  {
   "cell_type": "code",
   "source": [
    "# Load pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "\n",
    "# Extract features from personality items\n",
    "item_features = model.encode(personality['item'])\n",
    "\n",
    "# Convert features to DataFrame\n",
    "item_features = pd.DataFrame(item_features, index=personality['item'])\n",
    "item_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-09T13:01:39.138460Z",
     "start_time": "2025-12-09T13:01:30.474390Z"
    }
   },
   "id": "d62b94fb7235cf64",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                0         1         2    \\\n",
       "item                                                                      \n",
       "Go straight for the goal.                  0.010508  0.100210 -0.076360   \n",
       "Plunge into tasks with all my heart.      -0.005888  0.016261  0.023178   \n",
       "Demand quality.                           -0.042463 -0.015040  0.018326   \n",
       "Set high standards for myself and others.  0.002599  0.051376 -0.005017   \n",
       "Turn plans into actions.                  -0.002227  0.071067  0.033380   \n",
       "...                                             ...       ...       ...   \n",
       "Remain calm under pressure.                0.008002  0.041686  0.028673   \n",
       "Am calm even in tense situations.          0.077793  0.017205  0.027962   \n",
       "Can handle complex problems.              -0.064037  0.103417  0.005949   \n",
       "Readily overcome setbacks.                -0.020695  0.061760  0.005606   \n",
       "Know how to cope.                          0.049783  0.013049  0.036907   \n",
       "\n",
       "                                                3         4         5    \\\n",
       "item                                                                      \n",
       "Go straight for the goal.                  0.001715  0.062427  0.049277   \n",
       "Plunge into tasks with all my heart.      -0.011430  0.017892 -0.049775   \n",
       "Demand quality.                           -0.005335 -0.058177 -0.025078   \n",
       "Set high standards for myself and others. -0.031174 -0.080613 -0.050955   \n",
       "Turn plans into actions.                  -0.022899 -0.018842  0.015482   \n",
       "...                                             ...       ...       ...   \n",
       "Remain calm under pressure.                0.048361  0.012777 -0.045190   \n",
       "Am calm even in tense situations.          0.013444  0.018121 -0.048891   \n",
       "Can handle complex problems.              -0.016714 -0.080190 -0.048481   \n",
       "Readily overcome setbacks.                 0.072334 -0.035303  0.080265   \n",
       "Know how to cope.                          0.065969  0.006169  0.017248   \n",
       "\n",
       "                                                6         7         8    \\\n",
       "item                                                                      \n",
       "Go straight for the goal.                  0.051734  0.018802  0.077200   \n",
       "Plunge into tasks with all my heart.       0.028243 -0.036557  0.030705   \n",
       "Demand quality.                            0.007641  0.001493  0.012986   \n",
       "Set high standards for myself and others. -0.049017 -0.025073 -0.062257   \n",
       "Turn plans into actions.                  -0.013048 -0.028902 -0.018652   \n",
       "...                                             ...       ...       ...   \n",
       "Remain calm under pressure.                0.048694 -0.055915 -0.006774   \n",
       "Am calm even in tense situations.          0.070229 -0.011779  0.024065   \n",
       "Can handle complex problems.              -0.003207  0.018399 -0.049289   \n",
       "Readily overcome setbacks.                -0.032409 -0.013967 -0.015124   \n",
       "Know how to cope.                          0.019055  0.018089  0.030721   \n",
       "\n",
       "                                                9    ...       374       375  \\\n",
       "item                                                 ...                       \n",
       "Go straight for the goal.                  0.012241  ...  0.024534  0.014695   \n",
       "Plunge into tasks with all my heart.      -0.007846  ...  0.083111  0.034337   \n",
       "Demand quality.                           -0.005856  ...  0.008393 -0.100025   \n",
       "Set high standards for myself and others. -0.047764  ...  0.033066  0.008424   \n",
       "Turn plans into actions.                   0.056530  ...  0.104706  0.054388   \n",
       "...                                             ...  ...       ...       ...   \n",
       "Remain calm under pressure.               -0.092916  ...  0.049380 -0.018107   \n",
       "Am calm even in tense situations.         -0.040962  ...  0.051167  0.019745   \n",
       "Can handle complex problems.               0.005383  ...  0.083289  0.038508   \n",
       "Readily overcome setbacks.                -0.021790  ...  0.088610 -0.003809   \n",
       "Know how to cope.                         -0.075627  ...  0.033029 -0.057831   \n",
       "\n",
       "                                                376       377       378  \\\n",
       "item                                                                      \n",
       "Go straight for the goal.                 -0.061552 -0.013595 -0.088389   \n",
       "Plunge into tasks with all my heart.      -0.034837  0.014203 -0.124650   \n",
       "Demand quality.                           -0.009640 -0.019040 -0.045627   \n",
       "Set high standards for myself and others.  0.037696  0.078157 -0.031138   \n",
       "Turn plans into actions.                   0.026543 -0.054830 -0.026918   \n",
       "...                                             ...       ...       ...   \n",
       "Remain calm under pressure.               -0.068623  0.063546 -0.033172   \n",
       "Am calm even in tense situations.         -0.020991  0.016898 -0.026860   \n",
       "Can handle complex problems.               0.047977 -0.033457 -0.057766   \n",
       "Readily overcome setbacks.                 0.014618  0.015226 -0.004702   \n",
       "Know how to cope.                         -0.020089  0.062805  0.011065   \n",
       "\n",
       "                                                379       380       381  \\\n",
       "item                                                                      \n",
       "Go straight for the goal.                  0.105380 -0.017474 -0.020673   \n",
       "Plunge into tasks with all my heart.       0.089929  0.158494 -0.010659   \n",
       "Demand quality.                            0.018915  0.108192 -0.045537   \n",
       "Set high standards for myself and others.  0.042678  0.110578 -0.028196   \n",
       "Turn plans into actions.                   0.031745 -0.003095 -0.062595   \n",
       "...                                             ...       ...       ...   \n",
       "Remain calm under pressure.                0.014080  0.000326  0.022905   \n",
       "Am calm even in tense situations.         -0.008182  0.070316  0.077792   \n",
       "Can handle complex problems.               0.104399  0.089886  0.009211   \n",
       "Readily overcome setbacks.                 0.085417 -0.025451 -0.025940   \n",
       "Know how to cope.                          0.029956  0.008015 -0.044395   \n",
       "\n",
       "                                                382       383  \n",
       "item                                                           \n",
       "Go straight for the goal.                  0.008643 -0.026707  \n",
       "Plunge into tasks with all my heart.      -0.094051 -0.008922  \n",
       "Demand quality.                            0.057628  0.080098  \n",
       "Set high standards for myself and others. -0.050860 -0.036707  \n",
       "Turn plans into actions.                  -0.034699  0.001533  \n",
       "...                                             ...       ...  \n",
       "Remain calm under pressure.               -0.087142  0.037874  \n",
       "Am calm even in tense situations.         -0.070503 -0.023687  \n",
       "Can handle complex problems.               0.052749 -0.028001  \n",
       "Readily overcome setbacks.                 0.035729  0.015886  \n",
       "Know how to cope.                          0.004319  0.022751  \n",
       "\n",
       "[300 rows x 384 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Go straight for the goal.</th>\n",
       "      <td>0.010508</td>\n",
       "      <td>0.100210</td>\n",
       "      <td>-0.076360</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.062427</td>\n",
       "      <td>0.049277</td>\n",
       "      <td>0.051734</td>\n",
       "      <td>0.018802</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024534</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>-0.061552</td>\n",
       "      <td>-0.013595</td>\n",
       "      <td>-0.088389</td>\n",
       "      <td>0.105380</td>\n",
       "      <td>-0.017474</td>\n",
       "      <td>-0.020673</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>-0.026707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plunge into tasks with all my heart.</th>\n",
       "      <td>-0.005888</td>\n",
       "      <td>0.016261</td>\n",
       "      <td>0.023178</td>\n",
       "      <td>-0.011430</td>\n",
       "      <td>0.017892</td>\n",
       "      <td>-0.049775</td>\n",
       "      <td>0.028243</td>\n",
       "      <td>-0.036557</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>-0.007846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083111</td>\n",
       "      <td>0.034337</td>\n",
       "      <td>-0.034837</td>\n",
       "      <td>0.014203</td>\n",
       "      <td>-0.124650</td>\n",
       "      <td>0.089929</td>\n",
       "      <td>0.158494</td>\n",
       "      <td>-0.010659</td>\n",
       "      <td>-0.094051</td>\n",
       "      <td>-0.008922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demand quality.</th>\n",
       "      <td>-0.042463</td>\n",
       "      <td>-0.015040</td>\n",
       "      <td>0.018326</td>\n",
       "      <td>-0.005335</td>\n",
       "      <td>-0.058177</td>\n",
       "      <td>-0.025078</td>\n",
       "      <td>0.007641</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.012986</td>\n",
       "      <td>-0.005856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>-0.100025</td>\n",
       "      <td>-0.009640</td>\n",
       "      <td>-0.019040</td>\n",
       "      <td>-0.045627</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.108192</td>\n",
       "      <td>-0.045537</td>\n",
       "      <td>0.057628</td>\n",
       "      <td>0.080098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Set high standards for myself and others.</th>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.051376</td>\n",
       "      <td>-0.005017</td>\n",
       "      <td>-0.031174</td>\n",
       "      <td>-0.080613</td>\n",
       "      <td>-0.050955</td>\n",
       "      <td>-0.049017</td>\n",
       "      <td>-0.025073</td>\n",
       "      <td>-0.062257</td>\n",
       "      <td>-0.047764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033066</td>\n",
       "      <td>0.008424</td>\n",
       "      <td>0.037696</td>\n",
       "      <td>0.078157</td>\n",
       "      <td>-0.031138</td>\n",
       "      <td>0.042678</td>\n",
       "      <td>0.110578</td>\n",
       "      <td>-0.028196</td>\n",
       "      <td>-0.050860</td>\n",
       "      <td>-0.036707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turn plans into actions.</th>\n",
       "      <td>-0.002227</td>\n",
       "      <td>0.071067</td>\n",
       "      <td>0.033380</td>\n",
       "      <td>-0.022899</td>\n",
       "      <td>-0.018842</td>\n",
       "      <td>0.015482</td>\n",
       "      <td>-0.013048</td>\n",
       "      <td>-0.028902</td>\n",
       "      <td>-0.018652</td>\n",
       "      <td>0.056530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104706</td>\n",
       "      <td>0.054388</td>\n",
       "      <td>0.026543</td>\n",
       "      <td>-0.054830</td>\n",
       "      <td>-0.026918</td>\n",
       "      <td>0.031745</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>-0.062595</td>\n",
       "      <td>-0.034699</td>\n",
       "      <td>0.001533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Remain calm under pressure.</th>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.041686</td>\n",
       "      <td>0.028673</td>\n",
       "      <td>0.048361</td>\n",
       "      <td>0.012777</td>\n",
       "      <td>-0.045190</td>\n",
       "      <td>0.048694</td>\n",
       "      <td>-0.055915</td>\n",
       "      <td>-0.006774</td>\n",
       "      <td>-0.092916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049380</td>\n",
       "      <td>-0.018107</td>\n",
       "      <td>-0.068623</td>\n",
       "      <td>0.063546</td>\n",
       "      <td>-0.033172</td>\n",
       "      <td>0.014080</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.022905</td>\n",
       "      <td>-0.087142</td>\n",
       "      <td>0.037874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Am calm even in tense situations.</th>\n",
       "      <td>0.077793</td>\n",
       "      <td>0.017205</td>\n",
       "      <td>0.027962</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>0.018121</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>0.070229</td>\n",
       "      <td>-0.011779</td>\n",
       "      <td>0.024065</td>\n",
       "      <td>-0.040962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051167</td>\n",
       "      <td>0.019745</td>\n",
       "      <td>-0.020991</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>-0.026860</td>\n",
       "      <td>-0.008182</td>\n",
       "      <td>0.070316</td>\n",
       "      <td>0.077792</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>-0.023687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Can handle complex problems.</th>\n",
       "      <td>-0.064037</td>\n",
       "      <td>0.103417</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>-0.016714</td>\n",
       "      <td>-0.080190</td>\n",
       "      <td>-0.048481</td>\n",
       "      <td>-0.003207</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>-0.049289</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083289</td>\n",
       "      <td>0.038508</td>\n",
       "      <td>0.047977</td>\n",
       "      <td>-0.033457</td>\n",
       "      <td>-0.057766</td>\n",
       "      <td>0.104399</td>\n",
       "      <td>0.089886</td>\n",
       "      <td>0.009211</td>\n",
       "      <td>0.052749</td>\n",
       "      <td>-0.028001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Readily overcome setbacks.</th>\n",
       "      <td>-0.020695</td>\n",
       "      <td>0.061760</td>\n",
       "      <td>0.005606</td>\n",
       "      <td>0.072334</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.080265</td>\n",
       "      <td>-0.032409</td>\n",
       "      <td>-0.013967</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>-0.021790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088610</td>\n",
       "      <td>-0.003809</td>\n",
       "      <td>0.014618</td>\n",
       "      <td>0.015226</td>\n",
       "      <td>-0.004702</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>-0.025451</td>\n",
       "      <td>-0.025940</td>\n",
       "      <td>0.035729</td>\n",
       "      <td>0.015886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Know how to cope.</th>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.013049</td>\n",
       "      <td>0.036907</td>\n",
       "      <td>0.065969</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.017248</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>0.018089</td>\n",
       "      <td>0.030721</td>\n",
       "      <td>-0.075627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033029</td>\n",
       "      <td>-0.057831</td>\n",
       "      <td>-0.020089</td>\n",
       "      <td>0.062805</td>\n",
       "      <td>0.011065</td>\n",
       "      <td>0.029956</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>-0.044395</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.022751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 384 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing Similarity between Personality Items\n",
    "Now that we have extracted features for each personality item, we can compute the similarity between items. We use the `sklearn`'s `cosine similarity` function, which measures the cosine of the angle between two vectors. The closer the cosine similarity is to 1, the more similar the two items are. We compute the similarity between all pairs of items and store the results in a similarity matrix.\n",
    "\n",
    "Run the cell below."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2857ba947657ba6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compute cosine similarity between features\n",
    "predicted_sims = cosine_similarity(item_features)\n",
    "predicted_sims = pd.DataFrame(predicted_sims, index=personality['item'], columns=personality['item'])\n",
    "predicted_sims"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be2a46ead5acd970",
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "As you can see, the similarity matrix is symmetric, with the diagonal containing 1s (since the similarity of an item with itself is 1). Furthermore, items that you would expect to be more related (e.g. \"Turn plans into actions.\" and \"Plunge into tasks with all my heart.\" are indeed more similar. Conversely, less related items (e.g. \"Am calm in tense situations.\" and \"Demand quality.\") show lower cosine similarities.\n",
   "id": "12af29217891ed71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plotting the distribution of item similarities\n",
    "predicted_sims['Go straight for the goal.'].hist(bins=10)"
   ],
   "id": "f7e71aa8b372696"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Task 1**: The code above plots the distribution of cosine similarities for the first item. Try replacing `'Go straight for the goal.'` with other items to get a feel for the overall similarity distribution (hint: you can plan around with the `bins` parameter to change the resolution of the histogram). What do you notice about the distributions?",
   "id": "fdf23d59c28478f0"
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## Comparing to observed correlations between items\n",
    "This section compares how well the predicted similarities align with the *observed* similarities between items: that is, the correlations between the participant responses to the items. It first loads the observed correlations into a `pandas.DataFrame`:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adf4d0abb4abcb9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load observed correlations\n",
    "observed_sims = pd.read_csv('item_corrs.csv')\n",
    "observed_sims"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cc1dc20fa956639",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, the code pivots `observed_sims` to create a correlation matrix with the same structure as `predicted_sims` so that they can be easily compared."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2ed09a47a1e929d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pivoting to a correlation matrix for easy comparison with predicted correlations\n",
    "observed_sims = observed_sims.pivot(index='text_i', columns='text_j', values='cor')\n",
    "observed_sims"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "378171df95b531eb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The predicted and observed similarities are then aligned to ensure that the items are in the same order. The code then flattens the lower triangle of the matrices into vectors to compute the correlation between the predicted and observed similarities."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3afa1a518293b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Aligning observed and predicted similarities\n",
    "predicted_sims, observed_sims = predicted_sims.align(observed_sims)\n",
    "\n",
    "def lower_triangle_flat(df):\n",
    "    \"\"\"Takes the lower triangle of a dataframe and flattens it into a vector\"\"\"\n",
    "    rows, cols = np.triu_indices(len(df), k=1)  # k=1 to exclude the diagonal (self-similarities)\n",
    "    return pd.Series(df.values[rows, cols])\n",
    "\n",
    "# Flatten the lower triangle of the observed and predicted similarities into vectors\n",
    "predicted_sims_flat, observed_sims_flat = lower_triangle_flat(predicted_sims), lower_triangle_flat(observed_sims)\n",
    "\n",
    "# Correlation between predicted and observed\n",
    "print(f'r: {predicted_sims_flat.corr(observed_sims_flat).round(2)}')\n",
    "print(f'r of absolute values: {predicted_sims_flat.abs().corr(observed_sims_flat.abs()).round(2)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ad3a5846e445f4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "The correlation between the predicted and observed similarities is 0.18. If we take the absolute values of the similarities, the correlation increases to 0.33. Since we are not interested in which way round (in terms of polarity) the personality item scale was rated, we focus on the absolute values. This suggests that the extracted features capture some of the variance in the observed similarities between items. Whilst this suggests that the extracted features may not be capturing everything we want to know about the items, alternative explanations exist. Can you think of any? ",
   "metadata": {
    "collapsed": false
   },
   "id": "6f5bfa02bf02d593"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizing the Item Similarities\n",
    "We can also visualize `predicted_sims` in two dimensions using PaCMAP. PaCMAP is a dimensionality reduction technique that preserves the pairwise distances between points. The code fits the PaCMAP model to the extracted features and transform them into two dimensions, saving the results in a `pandas.DataFrame`. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "374f435fe7359d48"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize MDS model\n",
    "pac = PaCMAP(n_components=2, random_state=42)\n",
    "\n",
    "# Fit and transform the features\n",
    "pac_features = pac.fit_transform(item_features)\n",
    "\n",
    "# Convert features to DataFrame\n",
    "pac_features = pd.DataFrame(pac_features, columns=['x', 'y'])\n",
    "pac_features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8ef9a4e55ee48b9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, the code adds the personality factors and items as columns to `pac_features` to see how items cluster based on their similarity. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cda5a1ffd8a39af1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Adding personality factors to MDS features\n",
    "pac_features['factor'] = personality['factor']\n",
    "pac_features['item'] = personality['item']\n",
    "pac_features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce86ef9f2514eb23",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code next plots the MDS features, with each point representing a personality item. The points are colored by factor, allowing us to see how items cluster based on their similarity."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fe560ee6f7df016"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot pac features\n",
    "sns.scatterplot(data=pac_features, x='x', y='y', hue='factor', s=100)\n",
    "sns.despine(offset=10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "200a31b64cac4eef",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "As illustrated, the items somewhat cluster according to their factor, again suggesting that the extracted features have captured some meaningful information about the items."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2bb2fbc247e40df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reassigning Items to Constructs\n",
    "Finally, we can ask how well the extracted features predict the constructs to which the items belong. We first extract the features for each construct."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "820a9aa7290d1c2f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extracting construct features\n",
    "constructs = personality['construct'].unique()\n",
    "\n",
    "# Extracting features for constructs\n",
    "construct_features = model.encode(constructs)\n",
    "\n",
    "# Convert features to DataFrame\n",
    "construct_features = pd.DataFrame(construct_features, index=constructs)\n",
    "construct_features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25d1c803f1dedbd6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code next computes the cosine similarity between the construct features and the item features. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b9ef5d924ec9c45"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Computing cosine similarity between constructs and items\n",
    "construct_item_sims = cosine_similarity(construct_features, item_features)\n",
    "construct_sims = pd.DataFrame(construct_item_sims, index=construct_features.index, columns=item_features.index)\n",
    "construct_sims"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "248b382f6a9f789b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then find the closest construct to each item by finding the construct with the highest similarity. We add this as a new column, `closest_construct`, to the `personality` dataframe."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7dcf46131060780"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Finding the closest construct to each item adding as a new column ['closest_construct'] to the personality dataframe\n",
    "closest_construct = construct_sims.idxmax()\n",
    "closest_construct"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb56e6ae328ef138",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Adding the closest constructs to original personality dataframe\n",
    "personality['predicted_construct'] = personality['item'].map(closest_construct)\n",
    "personality"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2622afda8531d0ac",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluating how well the predicted constructs align with the actual constructs\n",
    "accuracy = (personality['construct'] == personality['predicted_construct']).mean()\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a511818ea68695a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predicting the constructs based on the similarity between the item and construct features results in an accuracy of 23%. Whilst this is an improvement on the .03% accuracy that would be expected at random, it is still relatively low. This could suggest that the extracted features do not fully capture the differences between the constructs, or (perhaps more interestingly) that the constructs are not as distinct as we might expect.\n",
    "\n",
    "You can also visualize the confusion matrix to see how well the items were assigned to the constructs. We firstly compute the confusion matrix using `pd.crosstab` and then sort it by the personality factor to make it easier to interpret. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f6254aaadc8af8a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion_matrix = pd.crosstab(personality['construct'], personality['predicted_construct'])\n",
    "\n",
    "# Adding missing predicted constructs\n",
    "missing_constructs = set(personality['construct']) - set(personality['predicted_construct'])\n",
    "confusion_matrix[list(missing_constructs)] = 0\n",
    "\n",
    "# Sorting confusion matrix by personality factor\n",
    "ordered_constructs = personality.sort_values('factor')['construct'].unique()\n",
    "confusion_matrix = confusion_matrix.loc[ordered_constructs, ordered_constructs]\n",
    "confusion_matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4da20e29739b0368",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "When interpreting the confusion matrix, it is important to remember that the rows represent the actual constructs, while the columns represent the predicted constructs. The values in the cells represent the number of items assigned to each construct. The diagonal reflects the number of items correctly assigned to their construct, while off-diagonal values reflect items that were misclassified. Finally, the maximum number of items that could be correctly assigned to a construct is 10, which is why the heatmap is capped at this value. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0c92a38f98abed0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plotting confusion matrix without numbers in cells\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "n_items_per_construct = 10 # Maximum possible number of correctly assigned items per construct\n",
    "sns.heatmap(confusion_matrix, cmap='Blues', vmin=0, vmax=n_items_per_construct, ax=ax)\n",
    "\n",
    "# Increasing x-tick label and y-tick label font size\n",
    "ax.xaxis.set_tick_params(labelsize=12)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb9954809b3b4455",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "As illustrated, while some constructs are well predicted (e.g., \"Emotionality\" and \"Imagination\"), most are less well predicted. \n",
    "\n",
    "**TASK 2**: Now rerun the entire notebook but with `model = SentenceTransformer('dwulff/mpnet-personality')` (you can find the right line via a `cmd + f` search). This is a model that has been fine-tuned on pairs of personality items to accurately predict the observed correlations between items. Although performance should be considerably better, it is important to be aware that this model has been fine-tuned on the same data that we are using to evaluate it, which gives it an unfair advantage."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaabfd927b73ff69"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
